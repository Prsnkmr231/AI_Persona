{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T05:37:34.783687Z",
     "iopub.status.busy": "2024-11-20T05:37:34.783333Z",
     "iopub.status.idle": "2024-11-20T05:37:34.812764Z",
     "shell.execute_reply": "2024-11-20T05:37:34.812036Z",
     "shell.execute_reply.started": "2024-11-20T05:37:34.783655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('upd_labelled_data.csv')\n",
    "\n",
    "print(f\"printing the top 5 rows of the dataset\")\n",
    "print(df.head())\n",
    "\n",
    "# Prepare dataset by combining user profile and job description, and selecting necessary columns\n",
    "# Add markers to differentiate user profile and job description\n",
    "df['input_text'] = \"[USER] \" + df['user'] + \" [JOB] \" + df['job']\n",
    "df = df[['input_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T05:38:37.738830Z",
     "iopub.status.busy": "2024-11-20T05:38:37.737739Z",
     "iopub.status.idle": "2024-11-20T05:38:40.232452Z",
     "shell.execute_reply": "2024-11-20T05:38:40.231542Z",
     "shell.execute_reply.started": "2024-11-20T05:38:37.738795Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0cf61137ad4c7d999cb6e0ea5f61dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f252456341490d856dec3e23af8f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259ca1c5ffae4b218ea9eb23085a49f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd8ee4ddcee465cb1f6d5e1c42461b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8797b9c5f4e4a9082ee70a420523017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name_or_path = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"model loaded successfully\")\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(f\"Dataset conversion is done \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T05:38:55.022211Z",
     "iopub.status.busy": "2024-11-20T05:38:55.021771Z",
     "iopub.status.idle": "2024-11-20T05:42:22.117413Z",
     "shell.execute_reply": "2024-11-20T05:42:22.116687Z",
     "shell.execute_reply.started": "2024-11-20T05:38:55.022169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad73b8a70bfe4a8e92d1f779c775e5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be494cd34e7b46d0910b0de60323d8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111263971111119, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_053926-73k5bh3r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sreejaa110-ti-steps/huggingface/runs/73k5bh3r' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/sreejaa110-ti-steps/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sreejaa110-ti-steps/huggingface' target=\"_blank\">https://wandb.ai/sreejaa110-ti-steps/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sreejaa110-ti-steps/huggingface/runs/73k5bh3r' target=\"_blank\">https://wandb.ai/sreejaa110-ti-steps/huggingface/runs/73k5bh3r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2532' max='2532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2532/2532 02:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2532, training_loss=0.015911485617702656, metrics={'train_runtime': 203.6489, 'train_samples_per_second': 99.436, 'train_steps_per_second': 12.433, 'total_flos': 670616205696000.0, 'train_loss': 0.015911485617702656, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def preprocess_data(example):\n",
    "    return tokenizer(example['input_text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "validation_dataset = train_test_split['test']\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  # You can increase this if you want better results\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,  # Log every 100 steps for better tracking\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_total_limit=2,\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T05:49:30.349404Z",
     "iopub.status.busy": "2024-11-20T05:49:30.349045Z",
     "iopub.status.idle": "2024-11-20T05:49:30.436886Z",
     "shell.execute_reply": "2024-11-20T05:49:30.435864Z",
     "shell.execute_reply.started": "2024-11-20T05:49:30.349372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Software Developer role with Python and JavaScript', -3.746919870376587), ('Data Scientist with SQL, Machine Learning', 4.756860256195068), ('Backend Developer with Flask and SQL', -4.245437145233154), ('Marketing Exe', -4.539279937744141), ('content creator', -3.812018632888794), ('java developer', -3.9749536514282227), ('Java', -3.139751672744751), ('software engineer', -1.6429455280303955), ('salesforce developer', -4.20063591003418)]\n",
      "Recommended Jobs: ['Data Scientist with SQL, Machine Learning', 'software engineer', 'Java', 'Software Developer role with Python and JavaScript', 'content creator']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to recommend jobs based on user profile and list of job descriptions\n",
    "def recommend_jobs(user_profile, job_listings, top_n=5):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    user_profile_encoded = tokenizer(\"[USER] \" + user_profile, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    scores = []\n",
    "    \n",
    "    for job in job_listings:\n",
    "        job_encoded = tokenizer(\"[JOB] \" + job, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        \n",
    "        # Concatenate user and job encoding for input\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.cat((user_profile_encoded['input_ids'], job_encoded['input_ids']), dim=1),\n",
    "            \"attention_mask\": torch.cat((user_profile_encoded['attention_mask'], job_encoded['attention_mask']), dim=1),\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "            score = output.logits[0][1].item()  # Confidence score for label '1' (recommended)\n",
    "            scores.append((job, score))\n",
    "    \n",
    "    # Sort and return the top N jobs based on score\n",
    "    print(scores)\n",
    "    recommended_jobs = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return [job for job, score in recommended_jobs]\n",
    "\n",
    "# Example user profile and job listings\n",
    "user_profile = \"Data Scientist with skills in Python, SQL, Machine Learning\"\n",
    "job_listings = [\n",
    "    \"Software Developer role with Python and JavaScript\",\n",
    "    \"Data Scientist with SQL, Machine Learning\",\n",
    "    \"Backend Developer with Flask and SQL\",\"Marketing Exe\",\"content creator\",\"java developer\",\"Java\",\"software engineer\",\"salesforce developer\"\n",
    "]\n",
    "\n",
    "# Get job recommendations\n",
    "recommendations = recommend_jobs(user_profile, job_listings)\n",
    "print(\"Recommended Jobs:\", recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T05:50:03.604477Z",
     "iopub.status.busy": "2024-11-20T05:50:03.603825Z",
     "iopub.status.idle": "2024-11-20T05:50:03.655190Z",
     "shell.execute_reply": "2024-11-20T05:50:03.654250Z",
     "shell.execute_reply.started": "2024-11-20T05:50:03.604444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('/kaggle/input/jobs-dataset/jobs_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T06:00:17.111168Z",
     "iopub.status.busy": "2024-11-20T06:00:17.110754Z",
     "iopub.status.idle": "2024-11-20T06:00:17.151284Z",
     "shell.execute_reply": "2024-11-20T06:00:17.150633Z",
     "shell.execute_reply.started": "2024-11-20T06:00:17.111137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine relevant columns into a single text representation for each job\n",
    "test_df['combined_text'] = test_df.apply(lambda row: f\"{row['job_title']} {row['skills']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T06:00:58.353022Z",
     "iopub.status.busy": "2024-11-20T06:00:58.352639Z",
     "iopub.status.idle": "2024-11-20T06:01:18.565784Z",
     "shell.execute_reply": "2024-11-20T06:01:18.564904Z",
     "shell.execute_reply.started": "2024-11-20T06:00:58.352988Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(366, 'Role:Software Development Engineer (SDE-1) / Full Stack Developer, Skills: Full Stack Developer,Software Development Engineer,Development,Full Stack,Software,Stack,Software development,Software engineering', 5.273569583892822), (2497, 'Role:Python Backend Developer (AWS Serverless), Skills: Django,Rest Api Development,Aws Serverless Architecture,Python Development,Microservices,Flask,Python,Backend', 5.254361629486084), (2325, 'Role:Java Developer, Skills: Multithreading,Banking Sector,Memory Management,Collections,Core Java Development,Design Patterns,OOPS,Java Development', 5.237627983093262), (2075, 'Role:Hiring For Java Developer For Pune Location, Skills: Java Development,J2Ee,Spring Boot,J2Ee Development,Java Programming,Java Coding,Core Java Development,Spring Batch', 5.235193729400635), (2859, 'Role:Java Full Stack Developer, Skills: Java Fullstack,Java Spring Boot,Java Development,Core Java Development,Core Java Programming,Spring Microservices,java Fullstack Developer,Programming', 5.234554290771484)]\n",
      "                                              job_title  \\\n",
      "366   Software Development Engineer (SDE-1) / Full S...   \n",
      "2497          Python Backend Developer (AWS Serverless)   \n",
      "2325                                     Java Developer   \n",
      "2075        Hiring For Java Developer For Pune Location   \n",
      "2859                          Java Full Stack Developer   \n",
      "\n",
      "               company_name  rating experience         salary  \\\n",
      "366             One Muthoot     NaN    0-2 Yrs  Not disclosed   \n",
      "2497                Quinnox     3.8   7-12 Yrs  Not disclosed   \n",
      "2325             TEKsystems     NaN    3-7 Yrs  Not disclosed   \n",
      "2075  Future Focus Infotech     NaN    5-9 Yrs  6-6.5 Lacs PA   \n",
      "2859   Mindpro Technologies     4.7    4-9 Yrs    3-8 Lacs PA   \n",
      "\n",
      "                       location  \\\n",
      "366                   Bengaluru   \n",
      "2497          Mumbai, Bengaluru   \n",
      "2325            Hybrid - Mumbai   \n",
      "2075                       Pune   \n",
      "2859  Karur, Chennai, Bengaluru   \n",
      "\n",
      "                                        job_description  \\\n",
      "366   . You should have knowledge and experience in ...   \n",
      "2497  Bachelors degree in Computer Science, Engineer...   \n",
      "2325  Role: Java DeveloperYears of Experience: 3-5+R...   \n",
      "2075  Fresher do not applyPreferred Experience Range...   \n",
      "2859  Position: Full Time / PermanentEducation: Bach...   \n",
      "\n",
      "                                                 skills  \\\n",
      "366   Full Stack Developer,Software Development Engi...   \n",
      "2497  Django,Rest Api Development,Aws Serverless Arc...   \n",
      "2325  Multithreading,Banking Sector,Memory Managemen...   \n",
      "2075  Java Development,J2Ee,Spring Boot,J2Ee Develop...   \n",
      "2859  Java Fullstack,Java Spring Boot,Java Developme...   \n",
      "\n",
      "                                       Combined Details  \n",
      "366   Role:Software Development Engineer (SDE-1) / F...  \n",
      "2497  Role:Python Backend Developer (AWS Serverless)...  \n",
      "2325  Role:Java Developer, Skills: Multithreading,Ba...  \n",
      "2075  Role:Hiring For Java Developer For Pune Locati...  \n",
      "2859  Role:Java Full Stack Developer, Skills: Java F...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load tokenizer and fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")  # Replace with your model's tokenizer\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained('/kaggle/working/results/checkpoint-2532')  # Path to fine-tuned model\n",
    "\n",
    "# Load the CSV file with job listings\n",
    "job_listings_df = pd.read_csv(\"/kaggle/input/jobs-dataset/jobs_data.csv\")  # Path to your jobs CSV file\n",
    "\n",
    "# Combine job details (role, skills, description) for each job\n",
    "job_listings = [\n",
    "    f\"Role:{row['job_title']}, Skills: {row['skills']}\"\n",
    "    for _, row in job_listings_df.iterrows()\n",
    "]\n",
    "\n",
    "# Function to recommend jobs using the fine-tuned model\n",
    "def recommend_jobs(user_profile, job_listings, top_n=5):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    fine_tuned_model.to(device)\n",
    "\n",
    "    # Encode the user profile\n",
    "    user_profile_encoded = tokenizer(\"[USER] \" + user_profile, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each job listing with its index\n",
    "    for idx, job in enumerate(job_listings):\n",
    "        # Encode each job listing\n",
    "        job_encoded = tokenizer(\"[JOB] \" + job, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        \n",
    "        # Concatenate the user and job input encodings\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.cat((user_profile_encoded['input_ids'], job_encoded['input_ids']), dim=1),\n",
    "            \"attention_mask\": torch.cat((user_profile_encoded['attention_mask'], job_encoded['attention_mask']), dim=1),\n",
    "        }\n",
    "        \n",
    "        # Predict with the fine-tuned model\n",
    "        with torch.no_grad():\n",
    "            output = fine_tuned_model(**inputs)\n",
    "            score = output.logits[0][1].item()  # Confidence score for label '1' (recommended)\n",
    "            scores.append((idx, job, score))  # Store index, job, and score\n",
    "    \n",
    "    # Sort jobs by score and select the top N recommendations\n",
    "    recommended_jobs = sorted(scores, key=lambda x: x[2], reverse=True)[:top_n]\n",
    "    print(recommended_jobs)\n",
    "    \n",
    "    return [(idx, job) for idx, job, score in recommended_jobs]  # Return index and job details\n",
    "\n",
    "# Define a sample user profile for testing\n",
    "user_profile = \"Java Developer, with backend\"\n",
    "\n",
    "# Get the top 5 job recommendations\n",
    "recommended_jobs = recommend_jobs(user_profile, job_listings, top_n=5)\n",
    "\n",
    "# Create a DataFrame of the results using the original job_listings_df\n",
    "result_df = job_listings_df.loc[[idx for idx, _ in recommended_jobs]].copy()\n",
    "result_df[\"Combined Details\"] = [job for _, job in recommended_jobs]\n",
    "\n",
    "# Display recommended jobs DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T06:10:01.435281Z",
     "iopub.status.busy": "2024-11-20T06:10:01.435017Z",
     "iopub.status.idle": "2024-11-20T06:10:33.541585Z",
     "shell.execute_reply": "2024-11-20T06:10:33.540569Z",
     "shell.execute_reply.started": "2024-11-20T06:10:01.435256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/checkpoint-1688.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the folder\n",
    "shutil.make_archive('checkpoint-1688', 'zip', '/kaggle/working/results/checkpoint-1688')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6068065,
     "sourceId": 9882376,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6077593,
     "sourceId": 9894933,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6111307,
     "sourceId": 9940025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
